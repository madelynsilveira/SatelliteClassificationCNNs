# Deep Learning and Multimodal AI Final Project
By Madelyn Silveira, Zivanai Mutaya, and James Chillery in the Spring of 2025

## Abstract
Artificial Intelligence does not come with public transparency built-in. In fact, it is quite the opposite. As AI scales up, we ought to ensure that we understand the impact of AI on our ecological environment, and create publically accessible tools to analyze it. The present paper explores various AI architectures to analyze satellite imagery at a low computational cost. We found that models trained on uncropped images were comparable to models trained on cropped images on two popular architectures: VGG16 and ResNet50. While computationally costly in nature, satellite images may hold the key to a universal ground truth of the state and trajectory of our ecosystem. Developing models that can digest data without human annotation will be the key to widespread progress.

## Full Paper
https://drive.google.com/drive/u/0/folders/1EiPPrBzJXgOxxLaFJB2w_FVsvaJ5ThAm

## Slides
https://www.canva.com/design/DAGk2qjdW8g/QJlwNq4BOkBM8FXBKhFAJA/edit?utm_content=DAGk2qjdW8g&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton

## Satellite Image Dataset
We used the Functional Map of the World (fMoW) RGB Dataset. This data is the JPEG-compressed RGB version of the dataset that was created for the fMoW Challenge. 
For more information about the files and folders included here, please see our [GitHub dataset page](https://github.com/fmow/dataset).
